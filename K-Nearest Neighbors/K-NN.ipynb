{"cells":[{"metadata":{"_uuid":"921952644dccef41a343cd00d283f06717026974","_cell_guid":"3f196ae2-25cb-42d5-89ec-f1cfc367f3ba"},"cell_type":"markdown","source":"**    Based on the given attributes predict the flower class. **\n    **Lets start with importing data and checking the first few rows of the data**"},{"metadata":{"scrolled":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-colorblind')\n\ncol_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\ndataset = pd.read_csv('../input/iris-dataset/iris.csv', header= None, names=col_names)\niris_class = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\ndataset['species_num'] = [iris_class[i] for i in dataset.species]\nX = dataset.drop(['species', 'species_num'], axis=1)\ndataset.head()","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"c6d98b2812d9166483a34b8f14c70caf76fc1c27","_cell_guid":"d670420a-168e-47a7-be76-b93a095a1fce"},"cell_type":"markdown","source":"    Visualizations will help in understanding our data in more better way. Following are the few visualiazations like :\n*  Histogram\n*  Line chart\n*  Kernel Density Chart\n*  Box plot"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot.hist(alpha=0.7);","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"76e281ec584b130c4d0b918ca5f46e1706f64fca","_cell_guid":"6b9f791e-1634-4056-94b6-39cbc45f7074","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot();","execution_count":4,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"f908b9b8-9c1f-4842-a3dd-82fdff142284","_uuid":"63f0eaec2aa0f3dae05f2a7896aecfea2099afb0","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot.kde();","execution_count":5,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"c1f484d9-00cf-4963-865a-8d072661bf97","_uuid":"6bfc6af16188bfcd88ac0ee9818a529fbabf526d","trusted":true},"cell_type":"code","source":"dataset[['sepal_length','sepal_width','petal_length', 'petal_width']].plot.box();","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"599f055b7780ab7bed514574c3a5f34f7aa13106","_cell_guid":"f6b93d2c-82e5-4ee1-9b04-62935b50354a","trusted":true},"cell_type":"code","source":"sns.pairplot(dataset[['sepal_length','sepal_width','petal_length', 'petal_width','species']], hue='species', diag_kind='kde', size=2);","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"6f0a580c7757905bd87a87b04ee6ef7216a38558","_cell_guid":"be03a47d-dfc7-4248-8929-0685d614e1ad","trusted":true},"cell_type":"code","source":"## Create an 'X' matrix by dropping the irrelevant columns.\nX = dataset.drop(['species', 'species_num'], axis=1)\ny = dataset.species_num\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n## Import the Classifier.\n\n## Instantiate the model with 5 neighbors. \nknn = KNeighborsClassifier(n_neighbors=5)\n## Fit the model on the training data.\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\nprint (\"The accuracy of the model - \", format(accuracy_score(y_test, pred) * 100))","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"144a60ccba0375862504cfa6e2a0bba5b3a1eb2a"},"cell_type":"markdown","source":"Lets implement K-NN for Regression also.  We will make a sample regression dataset using sklearn.\n1.  We will generate 100 test samples for regression"},{"metadata":{"trusted":true,"_uuid":"3036ae11a360fca9c2e9ac59c347f4164508f528"},"cell_type":"code","source":"# synthetic dataset for simple regression\nfrom sklearn.datasets import make_regression\nplt.figure()\nplt.title('Sample regression problem with one input variable')\nX_R1, y_R1 = make_regression(n_samples = 100, n_features=1,\n                            n_informative=1, bias = 150.0,\n                            noise = 30, random_state=0)\nplt.scatter(X_R1, y_R1, marker= 'o', s=50)\nplt.show()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"17cf16aa2ea3594489a5511e90025f2067c36ff6"},"cell_type":"markdown","source":"     Lets implement the k-NN for regression problem using the above sample regression dataset"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7e2b1bdf1d1d88982091c12fdbd9116ea018490f"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\nX_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1, random_state = 0)\nknnreg = KNeighborsRegressor(n_neighbors = 5).fit(X_train, y_train)\ntrain_score = knnreg.score(X_train, y_train)\ntest_score = knnreg.score(X_test, y_test)\nplt.plot(X_train, y_train, 'o', alpha=0.9, label='Train')\nplt.plot(X_test, y_test, '^', alpha=0.9, label='Test')\nplt.xlabel('Input feature')\nplt.ylabel('Target value')\nplt.title('KNN Regression (K={})\\n Train $R^2 = {:.3f}$,  Test $R^2 = {:.3f}$'.format(5, train_score, test_score))\nplt.legend()\nfig = plt.figure(figsize=(18, 18))\nplt.show()\n#print(knnreg.predict(X_test))\n#print('R-squared test score: {:.3f}'.format(knnreg.score(X_test, y_test)))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0d16ed0fa746ffbd7da01dee5ce44c5f6905012a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}