{
  "cells": [
    {
      "metadata": {
        "_uuid": "b4fca9fd02d900d76ade4a717b31e9aa9f4af8b9",
        "_cell_guid": "8020780c-fb7f-40d6-a1e5-bc692dbe5281",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import sys\nimport numpy as np\nimport pandas as pd\nimport scipy\nimport scipy.stats as stats\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom numpy import set_printoptions\nfrom sklearn.preprocessing import MinMaxScaler\n\ndataset = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\nprint(dataset.shape)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(768, 9)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b261af4f3091e37461f4bba8f61d5f16df48537"
      },
      "cell_type": "code",
      "source": "# Rescale - referred to as normalization of attributes are often rescaled into the range between 0 and 1.\n# You can rescale your data using scikit-learn using the MinMaxScaler class\narray = dataset.values\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX = scaler.fit_transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(rescaledX[0:5,:])",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 0.353  0.744  0.59   0.354  0.     0.501  0.234  0.483]\n [ 0.059  0.427  0.541  0.293  0.     0.396  0.117  0.167]\n [ 0.471  0.92   0.525  0.     0.     0.347  0.254  0.183]\n [ 0.059  0.447  0.541  0.232  0.111  0.419  0.038  0.   ]\n [ 0.     0.688  0.328  0.354  0.199  0.642  0.944  0.2  ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b53c9bcfa6347b1a5540e8e62452feadf770aae"
      },
      "cell_type": "code",
      "source": "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n# feature extraction\n# Select 4 best attributes/features to get better accuracy\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\ntest = SelectKBest(score_func=chi2, k=4)\nfit = test.fit(X, Y)\n# summarize scores\nset_printoptions(precision=3)\nprint(fit.scores_)\nfeatures = fit.transform(X)\n# summarize selected features\nprint(features[0:5,:])",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[  111.52   1411.887    17.605    53.108  2175.565   127.669     5.393\n   181.304]\n[[ 148.     0.    33.6   50. ]\n [  85.     0.    26.6   31. ]\n [ 183.     0.    23.3   32. ]\n [  89.    94.    28.1   21. ]\n [ 137.   168.    43.1   33. ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d400e5dfe23cbf2f4f7177a4e0bfecbddaaf222c"
      },
      "cell_type": "code",
      "source": "# Feature selection using Recursive feature elimination (RFE)\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\n\nmodel = LogisticRegression()\n\nrfe = RFE(model, 3)\nfit = rfe.fit(X, Y)\nprint(\"Num Features: %d\" % fit.n_features_)\nprint(\"Selected Features: %s\" % fit.support_)\nprint(\"Feature Ranking: %s\" % fit.ranking_)\n\nmodel1 = LinearRegression()\nrfe1 = RFE(model1, 3)\nfit1 = rfe1.fit(X, Y)\nprint(\"Num Features: %d\" % fit1.n_features_)\nprint(\"Selected Features: %s\" % fit1.support_)\nprint(\"Feature Ranking: %s\" % fit1.ranking_)",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Num Features: 3\nSelected Features: [ True False False False False  True  True False]\nFeature Ranking: [1 2 3 5 6 1 1 4]\nNum Features: 3\nSelected Features: [ True False False False False  True  True False]\nFeature Ranking: [1 2 4 6 5 1 1 3]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "abcec5e87f189daf195dccdd791a6b245ea02401"
      },
      "cell_type": "code",
      "source": "# Principal Component Analysis - It is actually a data reduction technique\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=3)\nfit = pca.fit(X)\n# summarize components\nprint(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\nprint(fit.components_)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Explained Variance: [ 0.889  0.062  0.026]\n[[ -2.022e-03   9.781e-02   1.609e-02   6.076e-02   9.931e-01   1.401e-02\n    5.372e-04  -3.565e-03]\n [ -2.265e-02  -9.722e-01  -1.419e-01   5.786e-02   9.463e-02  -4.697e-02\n   -8.168e-04  -1.402e-01]\n [ -2.246e-02   1.434e-01  -9.225e-01  -3.070e-01   2.098e-02  -1.324e-01\n   -6.400e-04  -1.255e-01]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73c04628b40a783d035a3fab9961f6b772a56db1"
      },
      "cell_type": "code",
      "source": "# Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance\n#of features. Following example uses ExtraTreesClassifier to estimate the importance of features\nfrom sklearn.ensemble import ExtraTreesClassifier\n\narray = dataset.values\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nmodel = ExtraTreesClassifier()\nmodel.fit(X, Y)\nprint(dataset.columns)\nprint(model.feature_importances_)\n",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n      dtype='object')\n[ 0.102  0.263  0.103  0.082  0.073  0.136  0.102  0.139]\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}